from django.http.response import HttpResponse
from extensible.models import ModelType
from glims.models import Sample, Library, Pool
from rest_framework.response import Response
# from glims.forms import SampleForm, FullSampleForm
from glims.api.serializers import SampleSerializer, PoolSerializer
from rest_framework import status
from django.db import transaction 
from tablib.core import Dataset
import tablib


class SampleImportExport(object):
    content_types = {'xls':'application/vnd.ms-excel','csv':'text/csv','json':'text/json'}
    def __init__(self,type=None):
        self.type = type if isinstance(type,ModelType) else ModelType.objects.filter(id=type).first()
        print self.type
    def prepare_row(self,row):
        data = {}
        #get rid of empty values
        for key in row.keys():
            if row[key] == '':
                row.pop(key)
        for key,val in row.iteritems():
            if key.startswith('data.'):
                data[key[5:]]=val
                del row[key]
        row['data'] = data
        return row
    def response(self,request, dataset, filename, file_type="xls"):
        response_kwargs = {
            'content_type': SampleImportExport.content_types[file_type]
        }
        filename = "%s.%s" %(filename,file_type)
        response = HttpResponse(getattr(dataset, file_type), **response_kwargs)
        response['Content-Disposition'] = 'attachment; filename={0}'.format(filename)
        return response    
    def generate_headers(self):
        self.headers = ['sample_id','name','description','received','adapter','barcode','pool']
        if self.type:
            if self.type.fields:
                self.headers += ['data.'+field['name'] for field in self.type.fields]#     field_names = [field.name for field in opts.fields]
        return self.headers
    def sample_template(self,request,filename_base='samplesheet_template',file_type='xls'):
        data = tablib.Dataset(headers=self.generate_headers())
        return self.response(request,data,filename_base,file_type)
    def sample_sheet(self,request,project,filename_base='samplesheet',file_type='xls'):
        data = tablib.Dataset(headers=self.generate_headers())
        for s in Sample.objects.filter(project=project):
            row = [s.sample_id,s.name,s.description,s.received,'','','']
            for field in project.sample_type.fields:
                row.append(s.data.get(field['name'],''))
            data.append(row)
        return self.response(request,data,filename_base,file_type)
    def import_samplesheet(self,request,file_handle,project):
        sid = transaction.savepoint()
        data = Dataset().load(file_handle.read())
        
        #initialize variables
        errors = {}
        samples = []
        pools = {}
        
        for index, row in enumerate(data.dict): 
            print index
            print row
            row = self.prepare_row(row)
            
            #If an autogenerated sample_id is listed, get the sample to update it            
            sample_id =  row.get('sample_id',None)
            instance = None
            if sample_id:
                instance = Sample.objects.filter(sample_id = row.get('sample_id'), project=project).first()
            
            row['project']=project.id
            row['type'] = project.sample_type_id
            if instance:
                sample = SampleSerializer(data=row,instance=instance,model_type=project.sample_type_id)
            else:
                sample = SampleSerializer(data=row,model_type=project.sample_type_id)
            if sample.is_valid():
                sample_instance = sample.save()
                samples.append(sample)
                #Keep track of pool name, if provided 
                pool = row.get('pool','')
                if not instance:
                    #Make a library
                    library = Library.objects.create(sample=sample_instance) #should include adapter and pool != '':
                    #Mark the library for addition to the given pool 
                    if pool != '':
                        if not pools.has_key(pool):
                            pools[pool] = []
                        pools[pool].append(library)
            else:
                sample_errors = dict(sample.errors)
                data_errors = sample_errors.pop('data',{})
                for field,field_errors in data_errors.iteritems():
                    sample_errors['data.%s'%field]=field_errors
                errors['row %d' % index] = sample_errors
            print 'end loop'
        
        #Create pools when necessary and add libraries
        for pool_name, libraries in pools.iteritems():
#             pool_name = '%s_%s'%(pool_name,project.project_id)
            #Check if the project has a pool of this name
            pool = Pool.objects.filter(libraries__sample__project=project,name=pool_name).first()
            #Create a new pool
            if not pool:
                pool_serializer = PoolSerializer(data={'name':pool_name,'group':project.group})
                if pool_serializer.is_valid():
                    pool = pool_serializer.save()
                else:
                    errors['Error creating pool "%s"'%pool_name] = pool_serializer.errors
                    continue
            #Add libraries
            pool.libraries.add(*libraries)
            pool.save()
            duplicates = pool.get_barcode_duplicates()
            if duplicates:
                errors['%s barcode duplicates' % pool.name] = {barcode:[', '.join(libraries)] for barcode,libraries in duplicates.iteritems()}
        if len(errors.keys()) > 0:
            transaction.savepoint_rollback(sid)
            return Response({'errors':errors},status=status.HTTP_400_BAD_REQUEST)
        else:
            transaction.savepoint_commit(sid)
            return Response([s.data for s in samples])
